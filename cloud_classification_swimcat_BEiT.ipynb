{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cloud_classification_swimcat_BEiT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLhK86o1z7YWE8BEbDP0lg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viniciusrpb/cloud_image_classification/blob/main/cloud_classification_swimcat_BEiT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloud Image Classification using Vision Transformers (Beit)"
      ],
      "metadata": {
        "id": "Ltlbw2CikP_K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w7VyOGXbkNwJ"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp -r \"/content/drive/My Drive/img_satelite/classificacao/SWIMCAT/train\" \"training\"\n",
        "#!cp -r \"/content/drive/My Drive/img_satelite/classificacao/SWIMCAT/val\" \"validation\"\n",
        "#!cp -r \"/content/drive/My Drive/img_satelite/classificacao/SWIMCAT/test\" \"testing\""
      ],
      "metadata": {
        "id": "68Nn5rzCkPY7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pytorch pytorch torchvision\n",
        "#!pip install timm==0.3.2\n",
        "#!pip install datasets transformers\n",
        "#!pip install transformers pytorch-lightning --quiet\n",
        "#!sudo apt -qq install git-lfs"
      ],
      "metadata": {
        "id": "sjjuPWctXrxL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import tensorflow as tf\n",
        "import torchvision\n",
        "from torchvision.transforms import ToTensor\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import glob\n",
        "import pytorch_lightning as pl\n",
        "from huggingface_hub import HfApi, Repository\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchmetrics import Accuracy\n",
        "from transformers import DeiTForImageClassification,BeitForImageClassification,BeitFeatureExtractor,DeiTFeatureExtractor,BeitFeatureExtractor\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "metadata": {
        "id": "RP4M1K9DkWdq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_train = 'training'\n",
        "path_validation = 'validation'\n",
        "path_test = 'testing'"
      ],
      "metadata": {
        "id": "YGMhz6mNkWiS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the image generator objects"
      ],
      "metadata": {
        "id": "IvyUuPWd-0PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = torchvision.datasets.ImageFolder(path_train, transform=ToTensor())\n",
        "valid_ds = torchvision.datasets.ImageFolder(path_validation, transform=ToTensor())\n",
        "test_ds = torchvision.datasets.ImageFolder(path_test, transform=ToTensor())"
      ],
      "metadata": {
        "id": "51EmVl7C-0XH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUrAaBRehj8n",
        "outputId": "efea5f56-1cfa-4186-d064-33575431eb79"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A-sky', 'B-pattern', 'C-thick-dark', 'D-thick-white', 'E-veil']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fn_collator(batch):\n",
        "    encodings = feature_extractor([x[0] for x in batch], return_tensors='pt')\n",
        "    encodings['labels'] = torch.tensor([x[1] for x in batch], dtype=torch.long)\n",
        "    return encodings "
      ],
      "metadata": {
        "id": "OGchBzEU4o3M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pega os c√≥digos das classes do dataset"
      ],
      "metadata": {
        "id": "3AbZ5--E-9G_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dic_label2id = {}\n",
        "dic_id2label = {}\n",
        "for i, class_name in enumerate(train_ds.classes):\n",
        "  dic_label2id[class_name] = str(i)\n",
        "  dic_id2label[str(i)] = class_name"
      ],
      "metadata": {
        "id": "sLt3AWBxTzw-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Allocate objects for loading the data using the DataGenerator"
      ],
      "metadata": {
        "id": "J78GiaITVegI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BeitForImageClassification,BeitFeatureExtractor\n",
        "model_name_or_path = 'microsoft/beit-base-patch16-224'\n",
        "feature_extractor = BeitFeatureExtractor.from_pretrained(model_name_or_path)\n",
        "\n",
        "#model = FlaxBeitForImageClassification.from_pretrained(\"microsoft/beit-base-patch16-224\")\n",
        "model = BeitForImageClassification.from_pretrained(\"microsoft/beit-base-patch16-224\")\n",
        "\n",
        "#model = BeitForImageClassification.from_pretrained(\n",
        "#    model_name_or_path,#\n",
        "#    num_labels=len(train_ds.classes),\n",
        "#    id2label=dic_id2label,\n",
        "#    label2id=dic_label2id)"
      ],
      "metadata": {
        "id": "nHY1wvf9hGr7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8590b812-5a30-45a2-c4bd-2d3b31914c6c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "acc = load_metric(\"accuracy\")\n",
        "f1score = load_metric(\"f1\",average='micro')\n",
        "precision = load_metric(\"precision\")\n",
        "recall = load_metric(\"recall\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "\n",
        "    results1 = acc.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n",
        "    results2 = f1score.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids,average='micro')\n",
        "    results3 = precision.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids,average='micro')\n",
        "    results4 = recall.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids,average='micro')\n",
        "\n",
        "    print(results1)\n",
        "\n",
        "    return {\n",
        "        \"precision\": results3,\n",
        "        \"recall\": results4,\n",
        "        \"f1\": results2,\n",
        "        \"accuracy\": results1,\n",
        "    }"
      ],
      "metadata": {
        "id": "raquc6rahEgJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  output_dir=\"./beit-base-clouds\",\n",
        "  per_device_train_batch_size=16,\n",
        "  evaluation_strategy=\"steps\",\n",
        "  num_train_epochs=2,\n",
        "  fp16=True,\n",
        "  save_steps=100,\n",
        "  eval_steps=100,\n",
        "  logging_steps=10,\n",
        "  learning_rate=5e-5,\n",
        "  save_total_limit=2,\n",
        "  remove_unused_columns=False,\n",
        "  push_to_hub=False,\n",
        "  report_to='tensorboard',\n",
        "  load_best_model_at_end=True,\n",
        ")"
      ],
      "metadata": {
        "id": "7eC55oETldiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd74cef-e077-4e17-e8c2-399511387327"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=fn_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=valid_ds,\n",
        "    tokenizer=feature_extractor,\n",
        ")"
      ],
      "metadata": {
        "id": "IaXAIE7slkQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb8fbd5-43b7-4f78-99da-976558e0ee9b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using amp half precision backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_results = trainer.train()\n",
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "id": "mgJoB1Tsl0Ku",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "37acb2ba-bf7f-4db6-bf80-c19492c73465"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 546\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 70\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [70/70 02:24, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Saving model checkpoint to ./beit-base-clouds\n",
            "Configuration saved in ./beit-base-clouds/config.json\n",
            "Model weights saved in ./beit-base-clouds/pytorch_model.bin\n",
            "Feature extractor saved in ./beit-base-clouds/preprocessor_config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** train metrics *****\n",
            "  epoch                    =        2.0\n",
            "  total_flos               = 79480932GF\n",
            "  train_loss               =     0.1015\n",
            "  train_runtime            = 0:02:27.05\n",
            "  train_samples_per_second =      7.426\n",
            "  train_steps_per_second   =      0.476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.evaluate(test_ds)\n",
        "trainer.log_metrics(\"eval\", metrics['precision'])\n",
        "#trainer.save_metrics(\"eval\", metrics)"
      ],
      "metadata": {
        "id": "5YV8Z5mtl4cH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "2ab8fc57-094b-42c9-faa0-6a3f7a5edd6b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 162\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='42' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [21/21 00:33]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Trainer is attempting to log a value of \"{'precision': 1.0}\" of type <class 'dict'> for key \"eval/precision\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'recall': 1.0}\" of type <class 'dict'> for key \"eval/recall\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'f1': 1.0}\" of type <class 'dict'> for key \"eval/f1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
            "Trainer is attempting to log a value of \"{'accuracy': 1.0}\" of type <class 'dict'> for key \"eval/accuracy\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 1.0}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-30d1b1eb3b67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eval\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#trainer.save_metrics(\"eval\", metrics)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'precision'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtIj1Yv8mMD8",
        "outputId": "ecc739a8-e79e-4de2-f1ed-6f2eed947a00"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_accuracy': {'accuracy': 1.0},\n",
              " 'eval_f1': {'f1': 1.0},\n",
              " 'eval_loss': 0.0016945298993960023,\n",
              " 'eval_precision': {'precision': 1.0},\n",
              " 'eval_recall': {'recall': 1.0},\n",
              " 'eval_runtime': 9.1443,\n",
              " 'eval_samples_per_second': 17.716,\n",
              " 'eval_steps_per_second': 2.297}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = test_ds.targets\n",
        "y_pred = trainer.predict(test_ds)\n",
        "\n",
        "cf_matrix = confusion_matrix(np.array(y_true), np.array(y_pred[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "v4i6nlNXgJM4",
        "outputId": "b65e2937-70a6-42d0-9f1f-340ef5f73949"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 162\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='105' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [21/21 06:18]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(np.array(y_true), np.array(y_pred[1]), target_names=test_ds.classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2v2XS4hmZXL",
        "outputId": "678793dc-8d77-4b1d-bc3e-fcdfc9ee0ba1"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "        A-sky       1.00      1.00      1.00        46\n",
            "    B-pattern       1.00      1.00      1.00        19\n",
            " C-thick-dark       1.00      1.00      1.00        51\n",
            "D-thick-white       1.00      1.00      1.00        28\n",
            "       E-veil       1.00      1.00      1.00        18\n",
            "\n",
            "     accuracy                           1.00       162\n",
            "    macro avg       1.00      1.00      1.00       162\n",
            " weighted avg       1.00      1.00      1.00       162\n",
            "\n"
          ]
        }
      ]
    }
  ]
}